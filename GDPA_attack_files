#utils.py
import numpy as np
import csv
import os
import matplotlib.pyplot as plt
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler

# Load the datasets
# Modified to use torchvision.datasets.Imagenette
def dataloader(train_size, test_size, data_dir, batch_size, num_workers, total_num=50000):
    # Setup the transformation
    train_transforms = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    ])

    test_transforms = transforms.Compose([
        transforms.Resize(size=(224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    ])

    # Ensure data directory exists
    os.makedirs(data_dir, exist_ok=True)

    print(f"Loading/Downloading Imagenette to {data_dir}...")
    
    # Load Imagenette Train and Val splits
    train_dataset = torchvision.datasets.Imagenette(
        root=data_dir, 
        split='train', 
        size='full', 
        download=True, 
        transform=train_transforms
    )
    
    test_dataset = torchvision.datasets.Imagenette(
        root=data_dir, 
        split='val', 
        size='full', 
        download=True, 
        transform=test_transforms
    )

    # Handle Subsetting
    # We create indices for the train set
    train_indices = np.arange(len(train_dataset))
    # If the requested train_size is smaller than the dataset, sample randomly
    if train_size < len(train_dataset):
        np.random.shuffle(train_indices)
        train_indices = train_indices[:train_size]
    
    # We create indices for the test set
    test_indices = np.arange(len(test_dataset))
    # If the requested test_size is smaller than the dataset, sample randomly
    if test_size < len(test_dataset):
        np.random.shuffle(test_indices)
        test_indices = test_indices[:test_size]

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(train_indices), num_workers=num_workers, pin_memory=True, shuffle=False)
    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(test_indices), num_workers=num_workers, pin_memory=True, shuffle=False)
    
    return train_loader, test_loader

# Test the model on clean dataset
def test(model, dataloader):
    model.eval()
    correct, total, loss = 0, 0, 0
    with torch.no_grad():
        for (images, labels) in dataloader:
            images = images.cuda()
            labels = labels.cuda()
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.shape[0]
            # Note: valid only if dataset labels map 1:1 to model output indices
            correct += (predicted == labels).sum().item()
    return correct / total

# Load the log and generate the training line
def log_generation(log_dir):
    # Load the statistics in the log
    epochs, train_rate, test_rate = [], [], []
    with open(log_dir, 'r') as f:
        reader = csv.reader(f)
        flag = 0
        for i in reader:
            if flag == 0:
                flag += 1
                continue
            else:
                epochs.append(int(i[0]))
                train_rate.append(float(i[1]))
                test_rate.append(float(i[2]))

    # Generate the success line
    plt.figure(num=0)
    plt.plot(epochs, test_rate, label='test_success_rate', linewidth=2, color='r')
    plt.plot(epochs, train_rate, label='train_success_rate', linewidth=2, color='b')
    plt.xlabel("epoch")
    plt.ylabel("success rate")
    plt.xlim(-1, max(epochs) + 1)
    plt.ylim(0, 1.0)
    plt.title("patch attack success rate")
    plt.legend()
    plt.savefig("training_pictures/patch_attack_success_rate.png")
    plt.close(0)

    # gdpa_utils.py
import torch
import torch.nn.functional as F

# ImageNet statistics
MEAN = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).cuda()
STD = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).cuda()

def normalize_imagenet(x):
    """Normalize [0,1] inputs to ImageNet stats"""
    return (x - MEAN) / STD

def denormalize_imagenet(x):
    """Denormalize ImageNet inputs back to [0,1] for Generator"""
    return x * STD + MEAN

def scale_theta(theta, theta_div):
    """Scales the predicted affine parameters"""
    # Limits shift to avoid patch going too far off screen
    mask_s = torch.tanh(theta / theta_div) * 0.8 
    return mask_s

def scale_pattern(patch, p_scale=1.0):
    """Scales patch values to valid range"""
    # Often generator outputs unbounded values, we squash to [0,1]
    return torch.sigmoid(patch)

def move_m_p(aff_theta, pattern_s, device, alpha=1.0, image_size=224):
    """
    Places the patch onto a canvas using Affine Grid Sample.
    aff_theta: (Batch, 2) -> Translation parameters (tx, ty)
    pattern_s: (Batch, 3, PatchSize, PatchSize)
    """
    bs = pattern_s.size(0)
    patch_h = pattern_s.size(2)
    
    # 1. Create a canvas with the patch in the center
    image_with_patch = torch.zeros(bs, 3, image_size, image_size, device=device)
    mask_with_patch = torch.zeros(bs, 1, image_size, image_size, device=device)
    
    # Center coordinates
    start = (image_size // 2) - (patch_h // 2)
    end = start + patch_h
    
    image_with_patch[:, :, start:end, start:end] = pattern_s
    mask_with_patch[:, :, start:end, start:end] = alpha
    
    # 2. Create Affine Matrix
    # We only use Translation (theta outputs 2 values: tx, ty)
    # Matrix: [[1, 0, tx], [0, 1, ty]]
    rot_theta = torch.tensor([[1.0, 0.0], [0.0, 1.0]]).unsqueeze(0).to(device).repeat(bs, 1, 1)
    theta_batch = torch.cat((rot_theta, aff_theta.unsqueeze(2)), 2)
    
    # 3. Apply Grid Sample (Inverse warp)
    grid = F.affine_grid(theta_batch, image_with_patch.size(), align_corners=True)
    
    # Warped Patch and Mask
    pattern_warped = F.grid_sample(image_with_patch, grid, align_corners=True)
    mask_warped = F.grid_sample(mask_with_patch, grid, align_corners=True)
    
    return mask_warped, pattern_warped

def perturb_image(inputs_normalized, mp_generator, device, devide_theta=1.0):
    """
    Full pipeline: 
    1. Denormalize input (Generator needs [0,1] content)
    2. Run Generator -> Patch & Theta
    3. Warp Patch
    4. Apply Patch to Image
    5. Return Normalized Result for Classifier
    """
    
    # Generator expects [0, 1] input range
    inputs_01 = denormalize_imagenet(inputs_normalized).clamp(0, 1)
    
    # Get Patch and Location
    _, pattern_raw, aff_theta_raw = mp_generator(inputs_01)
    
    # Process outputs
    aff_theta = scale_theta(aff_theta_raw, devide_theta)
    pattern_s = scale_pattern(pattern_raw)
    
    # Warp
    mask_s, pattern_s = move_m_p(aff_theta, pattern_s, device)
    
    # Apply to clean image (in [0,1] space)
    adv_img_01 = inputs_01 * (1 - mask_s) + pattern_s * mask_s
    adv_img_01 = adv_img_01.clamp(0, 1)
    
    # Re-normalize for classifier
    adv_img_norm = normalize_imagenet(adv_img_01)
    
    return adv_img_norm, inputs_01, adv_img_01, mask_s

# gdpa_models.py
import torch
import torch.nn as nn
import functools
from torch.nn import init

class ResnetBlock(nn.Module):
    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):
        super(ResnetBlock, self).__init__()
        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)

    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):
        conv_block = []
        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)

        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]
        if use_dropout:
            conv_block += [nn.Dropout(0.5)]

        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)
        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]

        return nn.Sequential(*conv_block)

    def forward(self, x):
        return x + self.conv_block(x)

class ResnetGenerator_small_patch(nn.Module):
    def __init__(self, patch_size, input_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False,
                 n_blocks=6, padding_type='reflect'):
        self.patch_size = patch_size
        assert (n_blocks >= 0)
        super(ResnetGenerator_small_patch, self).__init__()
        if type(norm_layer) == functools.partial:
            use_bias = norm_layer.func == nn.InstanceNorm2d
        else:
            use_bias = norm_layer == nn.InstanceNorm2d

        model_enc = [nn.ReflectionPad2d(3),
                     nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),
                     norm_layer(ngf),
                     nn.ReLU(True)]

        n_downsampling = 2
        for i in range(n_downsampling):
            mult = 2 ** i
            model_enc += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),
                          norm_layer(ngf * mult * 2),
                          nn.ReLU(True)]

        mult = 2 ** n_downsampling
        for i in range(n_blocks):
            model_enc += [
                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,
                            use_bias=use_bias)]

        self.model_enc = nn.Sequential(*model_enc)
        self.p_conv = nn.Conv2d(256, 3, kernel_size=3, stride=2, padding=1, bias=use_bias)
        self.p_norm = norm_layer(3)
        self.p_relu = nn.ReLU(True)
        
        # Calculate feature size based on downsampling. For 224x224 input with 2 downsamples: 56x56
        self.p_fc = nn.Linear(3 * 28 * 28, 3 * self.patch_size * self.patch_size)
        self.theta_fc = nn.Linear(256 * 56 * 56, 2)

    def forward(self, input):
        x = self.model_enc(input)
        # Location/Affine parameters (Theta)
        loc = self.theta_fc(x.view(x.size(0), -1))
        
        # Patch generation
        h = self.p_conv(x)
        h = self.p_norm(h)
        # Note: The original repo hardcoded view sizes, adapted here for safety
        h = self.p_relu(h)
        h = F.adaptive_avg_pool2d(h, (28, 28)) # Ensure size matches linear layer
        h = h.view(h.size(0), -1) 
        
        patch = self.p_fc(h).view(-1, 3, self.patch_size, self.patch_size)
        return 1, patch, loc

import torch.nn.functional as F

def get_norm_layer():
    return functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)

def init_weights(net, init_type='normal', init_gain=0.02):
    def init_func(m):
        classname = m.__class__.__name__
        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):
            if init_type == 'normal':
                init.normal_(m.weight.data, 0.0, init_gain)
            elif init_type == 'xavier':
                init.xavier_normal_(m.weight.data, gain=init_gain)
            if hasattr(m, 'bias') and m.bias is not None:
                init.constant_(m.bias.data, 0.0)
        elif classname.find('BatchNorm2d') != -1:
            init.normal_(m.weight.data, 1.0, init_gain)
            init.constant_(m.bias.data, 0.0)
    net.apply(init_func)

def load_generator(patch_size, input_nc, ngf, device):
    norm_layer = get_norm_layer()
    net = ResnetGenerator_small_patch(patch_size, input_nc, ngf, norm_layer=norm_layer)
    init_weights(net)
    return net.to(device)

# GDPA_Attack.py
import torch
import torch.nn as nn
import torchvision
from torchvision import models
import argparse
import csv
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

from utils import dataloader
from gdpa_models import load_generator
from gdpa_utils import perturb_image

parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', type=int, default=16, help="batch size") # Increased default for training gen
parser.add_argument('--num_workers', type=int, default=2, help="num_workers")
parser.add_argument('--train_size', type=int, default=5000, help="number of training images")
parser.add_argument('--test_size', type=int, default=1000, help="number of test images")
parser.add_argument('--patch_size', type=int, default=50, help="size of the square patch")
parser.add_argument('--lr_gen', type=float, default=0.0002, help="generator learning rate")
parser.add_argument('--target', type=int, default=859, help="target label (toaster)")
parser.add_argument('--epochs', type=int, default=10, help="total epoch")
parser.add_argument('--data_dir', type=str, default='./data', help="dir of the dataset")
parser.add_argument('--GPU', type=str, default='0', help="index of used GPU")
parser.add_argument('--log_dir', type=str, default='gdpa_attack_log.csv', help='dir of the log')
parser.add_argument('--beta', type=float, default=3000.0, help="scaling factor for location (higher = more centered initially)")
args = parser.parse_args()

os.environ["CUDA_VISIBLE_DEVICES"] = args.GPU
os.makedirs("gdpa_results", exist_ok=True)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def main():
    # 1. Load Data
    print("Loading Data...")
    train_loader, test_loader = dataloader(args.train_size, args.test_size, args.data_dir, args.batch_size, args.num_workers)

    # 2. Load Victim Model (Frozen)
    print("Loading Victim Model (ResNet50)...")
    model = models.resnet50(pretrained=True).to(device)
    model.eval()
    for param in model.parameters():
        param.requires_grad = False

    # 3. Load GDPA Generator
    print("Loading Generator...")
    # input_nc=3 (RGB), ngf=64 (Filters)
    mp_generator = load_generator(args.patch_size, 3, 64, device)
    
    # Optimizer for Generator
    optimizer_gen = torch.optim.Adam(mp_generator.parameters(), lr=args.lr_gen, betas=(0.5, 0.999))
    
    # Loss function (Targeted Attack)
    criterion = nn.CrossEntropyLoss()
    
    # Logging
    with open(args.log_dir, 'w') as f:
        writer = csv.writer(f)
        writer.writerow(["epoch", "train_asr", "test_asr", "avg_loss"])

    print(f"Starting Training for {args.epochs} epochs. Target Class: {args.target}")

    for epoch in range(args.epochs):
        # --- Training Phase ---
        mp_generator.train()
        total_train = 0
        success_train = 0
        total_loss = 0
        
        train_bar = tqdm(train_loader, desc=f"Epoch {epoch} Train")
        
        for images, labels in train_bar:
            images, labels = images.to(device), labels.to(device)
            bs = images.size(0)
            
            # Create target labels (Targeted Attack)
            target_labels = torch.full((bs,), args.target, dtype=torch.long).to(device)
            
            # Zero Grads
            optimizer_gen.zero_grad()
            
            # Generate Attack
            # adv_images_norm is ready for ResNet. 
            adv_images_norm, _, _, _ = perturb_image(images, mp_generator, device, devide_theta=args.beta)
            
            # Forward Pass Victim
            outputs = model(adv_images_norm)
            
            # Calculate Loss
            # We want to MINIMIZE CrossEntropy between output and TARGET class
            loss = criterion(outputs, target_labels)
            
            # Backprop
            loss.backward()
            optimizer_gen.step()
            
            # Stats
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += bs
            success_train += (predicted == target_labels).sum().item()
            
            train_bar.set_postfix({'ASR': f"{100*success_train/total_train:.2f}%", 'Loss': f"{loss.item():.4f}"})

        train_asr = success_train / total_train

        # --- Testing Phase ---
        mp_generator.eval()
        total_test = 0
        success_test = 0
        
        # For visualization saving
        saved_vis = False
        
        test_bar = tqdm(test_loader, desc=f"Epoch {epoch} Test")
        
        with torch.no_grad():
            for images, labels in test_bar:
                images, labels = images.to(device), labels.to(device)
                bs = images.size(0)
                target_labels = torch.full((bs,), args.target, dtype=torch.long).to(device)
                
                # Generate Attack
                # adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device)
                adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device, devide_theta=args.beta)

                
                outputs = model(adv_images_norm)
                _, predicted = torch.max(outputs.data, 1)
                
                total_test += bs
                success_test += (predicted == target_labels).sum().item()
                
                # Save Visualization for the first batch of the epoch
                if not saved_vis:
                    save_visualization(inputs_01, adv_01, mask, epoch)
                    saved_vis = True

        test_asr = success_test / total_test
        print(f"Epoch {epoch} Result: Train ASR: {train_asr:.2%}, Test ASR: {test_asr:.2%}")

        # Save Checkpoint
        torch.save(mp_generator.state_dict(), f"gdpa_results/generator_epoch_{epoch}.pth")
        
        # Log
        with open(args.log_dir, 'a') as f:
            writer = csv.writer(f)
            writer.writerow([epoch, train_asr, test_asr, total_loss/len(train_loader)])

def save_visualization(clean_batch, adv_batch, mask_batch, epoch):
    """Saves a comparison image of the first item in batch"""
    clean = clean_batch[0].cpu().permute(1, 2, 0).numpy()
    adv = adv_batch[0].cpu().permute(1, 2, 0).numpy()
    mask = mask_batch[0].cpu().permute(1, 2, 0).numpy()
    
    fig, axs = plt.subplots(1, 3, figsize=(12, 4))
    axs[0].imshow(clean)
    axs[0].set_title("Clean")
    axs[0].axis('off')
    
    axs[1].imshow(mask, cmap='gray')
    axs[1].set_title("Generated Mask/Patch")
    axs[1].axis('off')
    
    axs[2].imshow(adv)
    axs[2].set_title("Adversarial")
    axs[2].axis('off')
    
    plt.tight_layout()
    plt.savefig(f"gdpa_results/vis_epoch_{epoch}.png")
    plt.close()

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torchvision
from torchvision import models
import argparse
import csv
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

from utils import dataloader
from gdpa_models import load_generator
from gdpa_utils import perturb_image

parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', type=int, default=16, help="batch size")
parser.add_argument('--num_workers', type=int, default=2, help="num_workers")
parser.add_argument('--train_size', type=int, default=5000, help="number of training images")
parser.add_argument('--test_size', type=int, default=1000, help="number of test images")
parser.add_argument('--patch_size', type=int, default=50, help="size of the square patch")
parser.add_argument('--lr_gen', type=float, default=0.0002, help="generator learning rate")
# Note: --target argument removed as it is not needed for untargeted attacks
parser.add_argument('--epochs', type=int, default=10, help="total epoch")
parser.add_argument('--data_dir', type=str, default='./data', help="dir of the dataset")
parser.add_argument('--GPU', type=str, default='0', help="index of used GPU")
parser.add_argument('--log_dir', type=str, default='gdpa_untargeted_log.csv', help='dir of the log')
parser.add_argument('--beta', type=float, default=3000.0, help="scaling factor for location (higher = more centered initially)")
args = parser.parse_args()

os.environ["CUDA_VISIBLE_DEVICES"] = args.GPU
os.makedirs("gdpa_untargeted_results", exist_ok=True)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def main():
    # 1. Load Data
    print("Loading Data...")
    train_loader, test_loader = dataloader(args.train_size, args.test_size, args.data_dir, args.batch_size, args.num_workers)

    # 2. Load Victim Model (Frozen)
    print("Loading Victim Model (ResNet50)...")
    model = models.resnet50(pretrained=True).to(device)
    model.eval()
    for param in model.parameters():
        param.requires_grad = False

    # 3. Load GDPA Generator
    print("Loading Generator...")
    mp_generator = load_generator(args.patch_size, 3, 64, device)
    
    # Optimizer for Generator
    optimizer_gen = torch.optim.Adam(mp_generator.parameters(), lr=args.lr_gen, betas=(0.5, 0.999))
    
    # Loss function
    criterion = nn.CrossEntropyLoss()
    
    # Logging
    with open(args.log_dir, 'w') as f:
        writer = csv.writer(f)
        writer.writerow(["epoch", "train_asr", "test_asr", "avg_loss"])

    print(f"Starting UNTARGETED Training for {args.epochs} epochs.")

    for epoch in range(args.epochs):
        # --- Training Phase ---
        mp_generator.train()
        total_train = 0
        success_train = 0
        total_loss = 0
        
        train_bar = tqdm(train_loader, desc=f"Epoch {epoch} Train")
        
        for images, labels in train_bar:
            images, labels = images.to(device), labels.to(device)
            bs = images.size(0)
            
            # Zero Grads
            optimizer_gen.zero_grad()
            
            # Generate Attack
            adv_images_norm, _, _, _ = perturb_image(images, mp_generator, device, devide_theta=args.beta)
            
            # Forward Pass Victim
            outputs = model(adv_images_norm)
            
            # --- CRITICAL CHANGE: UNTARGETED LOSS ---
            # We want to MAXIMIZE the error on the true labels.
            # Optimizer minimizes, so we Minimize (-Loss)
            loss = -criterion(outputs, labels)
            
            # Backprop
            loss.backward()
            optimizer_gen.step()
            
            # Stats
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += bs
            
            # Success = Prediction is NOT the ground truth
            success_train += (predicted != labels).sum().item()
            
            train_bar.set_postfix({'ASR': f"{100*success_train/total_train:.2f}%", 'Loss': f"{loss.item():.4f}"})

        train_asr = success_train / total_train

        # --- Testing Phase ---
        mp_generator.eval()
        total_test = 0
        success_test = 0
        saved_vis = False
        
        test_bar = tqdm(test_loader, desc=f"Epoch {epoch} Test")
        
        with torch.no_grad():
            for images, labels in test_bar:
                images, labels = images.to(device), labels.to(device)
                bs = images.size(0)
                
                # Generate Attack
                # adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device)
                adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device, devide_theta=args.beta)
                
                outputs = model(adv_images_norm)
                _, predicted = torch.max(outputs.data, 1)
                
                total_test += bs
                # Success = Prediction is NOT the ground truth
                success_test += (predicted != labels).sum().item()
                
                # Save Visualization
                if not saved_vis:
                    save_visualization(inputs_01, adv_01, mask, epoch)
                    saved_vis = True

        test_asr = success_test / total_test
        print(f"Epoch {epoch} Result: Train ASR: {train_asr:.2%}, Test ASR: {test_asr:.2%}")

        # Save Checkpoint
        torch.save(mp_generator.state_dict(), f"gdpa_untargeted_results/generator_epoch_{epoch}.pth")
        
        # Log
        with open(args.log_dir, 'a') as f:
            writer = csv.writer(f)
            writer.writerow([epoch, train_asr, test_asr, total_loss/len(train_loader)])

def save_visualization(clean_batch, adv_batch, mask_batch, epoch):
    """Saves a comparison image of the first item in batch"""
    clean = clean_batch[0].cpu().permute(1, 2, 0).numpy()
    adv = adv_batch[0].cpu().permute(1, 2, 0).numpy()
    mask = mask_batch[0].cpu().permute(1, 2, 0).numpy()
    
    fig, axs = plt.subplots(1, 3, figsize=(12, 4))
    axs[0].imshow(clean)
    axs[0].set_title("Clean")
    axs[0].axis('off')
    
    axs[1].imshow(mask, cmap='gray')
    axs[1].set_title("Generated Mask/Patch")
    axs[1].axis('off')
    
    axs[2].imshow(adv)
    axs[2].set_title("Adversarial (Untargeted)")
    axs[2].axis('off')
    
    plt.tight_layout()
    plt.savefig(f"gdpa_untargeted_results/vis_epoch_{epoch}.png")
    plt.close()

if __name__ == "__main__":
    main()

# gdpa_vis_untargeted.py
import torch
import torchvision
from torchvision import models, transforms
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import os
import json
import urllib.request

from gdpa_models import load_generator
from gdpa_utils import perturb_image

# --- Configuration ---
DATA_DIR = './data'
# MAKE SURE TO POINT TO THE NEW UNTARGETED MODEL FOLDER
GENERATOR_PATH = 'gdpa_results/generator_epoch_3.pth' 
PATCH_SIZE = 60         
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
OUTPUT_FILE = "gdpa_untargeted_vis.png"
CLEAN_TENSOR_FILE = "clean_img_tensor.pt"
ADV_TENSOR_FILE = "adv_img_tensor.pt"


# --- Helpers ---
def get_imagenet_labels():
    url = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
    try:
        with urllib.request.urlopen(url) as response:
            labels = json.loads(response.read())
        return labels
    except:
        return None

labels_map = get_imagenet_labels()

def get_label_name(index):
    if labels_map:
        return f"{index}: {labels_map[index]}"
    return f"Class {index}"

def main():
    # 1. Load Model
    model = models.resnet50(pretrained=True).to(DEVICE)
    model.eval()

    # 2. Load Generator
    if not os.path.exists(GENERATOR_PATH):
        print(f"Error: {GENERATOR_PATH} not found. Run GDPA_Attack_Untargeted.py first.")
        return

    mp_generator = load_generator(PATCH_SIZE, 3, 64, DEVICE)
    mp_generator.load_state_dict(torch.load(GENERATOR_PATH, map_location=DEVICE))
    mp_generator.eval()

    # 3. Load Data
    norm_mean = [0.485, 0.456, 0.406]
    norm_std = [0.229, 0.224, 0.225]
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean, norm_std)
    ])
    try:
        testset = torchvision.datasets.Imagenette(root=DATA_DIR, split='val', size='full', download=True, transform=transform)
        testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)
        image, label = next(iter(testloader))
    except:
        image = torch.randn(1, 3, 224, 224)
        label = torch.tensor([0])

    image = image.to(DEVICE)
    label_idx = label.item()

    # 4. Attack
    with torch.no_grad():
        adv_norm, inputs_01, adv_01, mask = perturb_image(image, mp_generator, DEVICE)
        adv_norm, inputs_01, adv_01, mask = perturb_image(image, mp_generator, DEVICE, devide_theta=3000)

    # 5. Inference
    out_clean = model(image)
    top_clean = torch.argmax(out_clean, 1).item()
    conf_clean = torch.nn.functional.softmax(out_clean, dim=1)[0][top_clean].item()

    out_adv = model(adv_norm)
    top_adv = torch.argmax(out_adv, 1).item()
    conf_adv = torch.nn.functional.softmax(out_adv, dim=1)[0][top_adv].item()

    # 6. Save Tensors (Upscaled to 512x512)
    print(f"Saving 512x512 tensors to {CLEAN_TENSOR_FILE} and {ADV_TENSOR_FILE}...")
    
    # Interpolate
    clean_512 = F.interpolate(inputs_01, size=(512, 512), mode='bilinear', align_corners=False)
    adv_512 = F.interpolate(adv_01, size=(512, 512), mode='bilinear', align_corners=False)
    
    # --- FIX: CLAMP VALUES BEFORE SAVING ---
    clean_512 = torch.clamp(clean_512, 0.0, 1.0)
    adv_512 = torch.clamp(adv_512, 0.0, 1.0)
    # ---------------------------------------

    torch.save(clean_512.detach().cpu(), CLEAN_TENSOR_FILE)
    torch.save(adv_512.detach().cpu(), ADV_TENSOR_FILE)

    # 7. Visualize
    img_clean_vis = inputs_01[0].permute(1, 2, 0).cpu().numpy()
    img_adv_vis = adv_01[0].permute(1, 2, 0).cpu().numpy()
    mask_vis = mask[0].permute(1, 2, 0).cpu().numpy()

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    axes[0].imshow(img_clean_vis)
    axes[0].set_title(f"Clean (True: {get_label_name(label_idx)})\nPred: {get_label_name(top_clean)}\nConf: {conf_clean:.2%}")
    axes[0].axis('off')

    axes[1].imshow(mask_vis, cmap='gray')
    axes[1].set_title("Generated Mask")
    axes[1].axis('off')

    # Logic for Untargeted Success: Prediction != True Label
    is_success = (top_adv != label_idx)
    color = 'green' if is_success else 'red'
    
    axes[2].imshow(img_adv_vis)
    axes[2].set_title(f"Untargeted Attack\nPred: {get_label_name(top_adv)}\nConf: {conf_adv:.2%}", color=color)
    axes[2].axis('off')

    plt.tight_layout()
    plt.savefig(OUTPUT_FILE)
    print(f"Saved visualization to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()

#patch_detection.py
# find mask and inpaint
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from diffusers import StableDiffusionPipeline, AutoencoderTiny, AutoencoderKL, StableDiffusionInpaintPipeline
from skimage.filters import threshold_otsu
from skimage.transform import resize
import scipy.ndimage
import PIL.Image
import gc
import os

# ------------------------------------------------------------------------------
# 0. Setup & Memory
# ------------------------------------------------------------------------------
def cleanup():
    gc.collect()
    torch.cuda.empty_cache()

cleanup()
device = "cuda" if torch.cuda.is_available() else "cpu"

print(f"Loading Models to {device}...")
model_id = "runwayml/stable-diffusion-v1-5"

# 1. Load Main Pipeline
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    variant="fp16"
).to(device)

# 2. Load Speed VAE (For Detection Loop)
tiny_vae = AutoencoderTiny.from_pretrained(
    "madebyollin/taesd",
    torch_dtype=torch.float16
).to(device)

# 3. Load Quality VAE (For Final Restoration)
quality_vae = AutoencoderKL.from_pretrained(
    "stabilityai/sd-vae-ft-mse",
    torch_dtype=torch.float16
).to(device)

pipe.vae = quality_vae

# Shortcuts
unet = pipe.unet
scheduler = pipe.scheduler
text_encoder = pipe.text_encoder

# Freeze
tiny_vae.requires_grad_(False)
quality_vae.requires_grad_(False)
unet.requires_grad_(False)
text_encoder.requires_grad_(False)

# ------------------------------------------------------------------------------
# 1. The Detection Optimization
# ------------------------------------------------------------------------------

def optimize_patch_detection_ldm(y_obs, num_steps=300):

    # Encode with TINY VAE for speed
    with torch.no_grad():
        # y_obs expected in range [-1, 1]
        init_latents = tiny_vae.encode(y_obs).latents

    # Parameters
    z_opt = init_latents.clone().detach().float().requires_grad_(True)
    # w_opt = torch.zeros(1, 1, 64, 64, device=device).float().requires_grad_(True)
    w_opt = torch.full((1, 1, 64, 64), -4.0, device=device).float().requires_grad_(True)

    w_ema = w_opt.detach().clone()
    ema_decay = 0.95

    optimizer = optim.Adam([
        {'params': z_opt, 'lr': 0.05},
        {'params': w_opt, 'lr': 0.1}
    ])

    text_input = pipe.tokenizer([""], padding="max_length", max_length=pipe.tokenizer.model_max_length, return_tensors="pt")
    text_embeddings = text_encoder(text_input.input_ids.to(device))[0]

    print(f"--- Stage 1: Detecting Mask ({num_steps} steps) ---")

    for step in range(num_steps):
        optimizer.zero_grad()

        # 1. Decode Image
        x_est = tiny_vae.decode(z_opt.half()).sample.float()

        # 2. Mask Logic
        m_small = torch.sigmoid(w_opt)
        m_large = F.interpolate(m_small, size=(512, 512), mode='bilinear', align_corners=False)

        # 3. Fidelity Loss
        loss_fidelity = torch.mean(((1 - m_large) * (y_obs.float() - x_est)) ** 2)

        # 4. Mask Priors
        loss_sparsity = torch.mean(m_small)
        loss_tv = (torch.mean(torch.abs(m_small[:, :, :-1, :] - m_small[:, :, 1:, :])) +
                   torch.mean(torch.abs(m_small[:, :, :, :-1] - m_small[:, :, :, 1:])))

        # 5. SDS Loss
        t = torch.randint(20, 980, (1,), device=device).long()
        noise = torch.randn_like(z_opt).half()
        noisy_z = scheduler.add_noise(z_opt.half(), noise, t)

        with torch.no_grad():
            noise_pred = unet(noisy_z, t, encoder_hidden_states=text_embeddings).sample

        grad_sds = (noise_pred.float() - noise.float())
        target_z = (z_opt - grad_sds).detach()
        loss_sds = 0.5 * F.mse_loss(z_opt, target_z)

        # Weights
        w_fid, w_sds, w_spa, w_tv = 2000.0, 150.0, 80.0, 200.0
        total_loss = (w_fid * loss_fidelity + w_sds * loss_sds + w_spa * loss_sparsity + w_tv * loss_tv)

        total_loss.backward()
        optimizer.step()

        # EMA for Mask
        with torch.no_grad():
            w_ema = ema_decay * w_ema + (1 - ema_decay) * w_opt

        if step % 100 == 0:
            ema_m_mean = torch.sigmoid(w_ema).mean().item()
            plt.imshow(torch.sigmoid(w_ema).squeeze().cpu().numpy())
            plt.title(f'EMA Mask (Step {step})')
            plt.axis('off')
            plt.show()
            print(f"Step {step}: Loss {total_loss.item():.2f} | "
                  f"EMA MaskMean {ema_m_mean:.3f}")

    # Extract Binary Mask
    with torch.no_grad():
        prob_map_small = torch.sigmoid(w_ema)
        plt.imshow(prob_map_small.squeeze().cpu().numpy())
        #show heat map value on the side
        plt.colorbar()
        plt.title('Final Mask')
        plt.axis('off')
        plt.show()
        prob_map_large = F.interpolate(prob_map_small, size=(512, 512), mode='bilinear').cpu().numpy().squeeze()

        thresh = prob_map_large.max()*0.5
        final_mask_np = (prob_map_large > thresh).astype(float)

        # if prob_map_large.max() < 0.1:
        #     final_mask_np = np.zeros_like(prob_map_large)
        # else:
        #     try:
        #         thresh = threshold_otsu(prob_map_large)
        #         final_mask_np = (prob_map_large > thresh).astype(float)
        #     except:
        #         final_mask_np = (prob_map_large > 0.5).astype(float)

    return final_mask_np

# ------------------------------------------------------------------------------
# 2. The Restoration Pass
# ------------------------------------------------------------------------------

def high_quality_restoration(original_tensor, mask_np):
    print("--- Stage 2: High Quality Restoration ---")

    # Clean Memory for Inpainting Model
    global pipe, tiny_vae
    del pipe
    del tiny_vae
    torch.cuda.empty_cache()

    # Dilate Mask to cover edges
    mask_dilated = scipy.ndimage.binary_dilation(mask_np, iterations=10)

    # Convert to PIL
    # Original tensor is [-1, 1], convert to [0, 255]
    original_img_np = (original_tensor.squeeze().permute(1, 2, 0).cpu().numpy() + 1) / 2
    original_img_np = np.clip(original_img_np * 255, 0, 255).astype(np.uint8)

    mask_img_np = (mask_dilated * 255).astype(np.uint8)

    image_pil = PIL.Image.fromarray(original_img_np)
    mask_pil = PIL.Image.fromarray(mask_img_np)

    # Load Inpainting Model
    inpaint_pipe = StableDiffusionInpaintPipeline.from_pretrained(
        "runwayml/stable-diffusion-inpainting",
        torch_dtype=torch.float16,
        variant="fp16"
    ).to(device)

    try:
        result = inpaint_pipe(
            prompt="",
            image=image_pil,
            mask_image=mask_pil,
            num_inference_steps=40,
            strength=1.0,
            guidance_scale=7.5
        ).images[0]

        return result

    except Exception as e:
        print(f"Pipeline Error: {e}")
        return image_pil

# ------------------------------------------------------------------------------
# 3. Execution
# ------------------------------------------------------------------------------

def prepare_tensor_from_file(path, target_size=(512, 512)):
    print(f"Loading {path}...")
    if not os.path.exists(path):
        raise FileNotFoundError(f"File {path} not found. Run the generation script first.")

    img_tensor = torch.load(path)

    # Ensure correct shape (B, C, H, W)
    if img_tensor.dim() == 3: img_tensor = img_tensor.unsqueeze(0)

    # Ensure range [0, 1] before normalizing to [-1, 1]
    if img_tensor.max() > 1.0: img_tensor = img_tensor / 255.0

    img_resized = F.interpolate(img_tensor, size=target_size, mode='bilinear', align_corners=False)

    # Normalize to [-1, 1] for Stable Diffusion
    img_normalized = (img_resized - 0.5) / 0.5
    return img_normalized.to(device, dtype=torch.float16)

# --- CHANGED: Use the ADVERSARIAL image created by Script 1 ---
INPUT_PATH = "adv_img_tensor.pt"

try:
    # 1. Load Data
    corrupted_tensor_512 = prepare_tensor_from_file(INPUT_PATH)

    # 2. Run Optimization to find Mask
    detected_mask_512 = optimize_patch_detection_ldm(corrupted_tensor_512, num_steps=500)

    # 3. Run Restoration
    restored_pil = high_quality_restoration(corrupted_tensor_512, detected_mask_512)

    # 4. Visualization
    original_size = (224, 224)

    # Input (convert back to 0-1 for plotting)
    input_np = (corrupted_tensor_512.detach().cpu().squeeze().float().permute(1, 2, 0).numpy() + 1) / 2
    input_img_224 = resize(input_np, original_size)

    # Mask
    mask_224 = resize(detected_mask_512, original_size, order=0)

    # Restored
    restored_np = np.array(restored_pil.resize(original_size)) / 255.0

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    titles = ["Adversarial Input (from file)", "Detected Mask", "High-Quality Inpaint"]
    imgs = [input_img_224, mask_224, restored_np]

    for i in range(3):
        ax[i].imshow(imgs[i], cmap='gray' if i==1 else None)
        ax[i].set_title(titles[i])
        ax[i].axis('off')

    plt.tight_layout()
    plt.show()

except Exception as e:
    print(f"Error: {e}")
    import traceback
    traceback.print_exc()
