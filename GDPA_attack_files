#utils.py
import numpy as np
import csv
import os
import matplotlib.pyplot as plt
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler

# Load the datasets
# Modified to use torchvision.datasets.Imagenette
def dataloader(train_size, test_size, data_dir, batch_size, num_workers, total_num=50000):
    # Setup the transformation
    train_transforms = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    ])

    test_transforms = transforms.Compose([
        transforms.Resize(size=(224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    ])

    # Ensure data directory exists
    os.makedirs(data_dir, exist_ok=True)

    print(f"Loading/Downloading Imagenette to {data_dir}...")
    
    # Load Imagenette Train and Val splits
    train_dataset = torchvision.datasets.Imagenette(
        root=data_dir, 
        split='train', 
        size='full', 
        download=True, 
        transform=train_transforms
    )
    
    test_dataset = torchvision.datasets.Imagenette(
        root=data_dir, 
        split='val', 
        size='full', 
        download=True, 
        transform=test_transforms
    )

    # Handle Subsetting
    # We create indices for the train set
    train_indices = np.arange(len(train_dataset))
    # If the requested train_size is smaller than the dataset, sample randomly
    if train_size < len(train_dataset):
        np.random.shuffle(train_indices)
        train_indices = train_indices[:train_size]
    
    # We create indices for the test set
    test_indices = np.arange(len(test_dataset))
    # If the requested test_size is smaller than the dataset, sample randomly
    if test_size < len(test_dataset):
        np.random.shuffle(test_indices)
        test_indices = test_indices[:test_size]

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(train_indices), num_workers=num_workers, pin_memory=True, shuffle=False)
    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(test_indices), num_workers=num_workers, pin_memory=True, shuffle=False)
    
    return train_loader, test_loader

# Test the model on clean dataset
def test(model, dataloader):
    model.eval()
    correct, total, loss = 0, 0, 0
    with torch.no_grad():
        for (images, labels) in dataloader:
            images = images.cuda()
            labels = labels.cuda()
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.shape[0]
            # Note: valid only if dataset labels map 1:1 to model output indices
            correct += (predicted == labels).sum().item()
    return correct / total

# Load the log and generate the training line
def log_generation(log_dir):
    # Load the statistics in the log
    epochs, train_rate, test_rate = [], [], []
    with open(log_dir, 'r') as f:
        reader = csv.reader(f)
        flag = 0
        for i in reader:
            if flag == 0:
                flag += 1
                continue
            else:
                epochs.append(int(i[0]))
                train_rate.append(float(i[1]))
                test_rate.append(float(i[2]))

    # Generate the success line
    plt.figure(num=0)
    plt.plot(epochs, test_rate, label='test_success_rate', linewidth=2, color='r')
    plt.plot(epochs, train_rate, label='train_success_rate', linewidth=2, color='b')
    plt.xlabel("epoch")
    plt.ylabel("success rate")
    plt.xlim(-1, max(epochs) + 1)
    plt.ylim(0, 1.0)
    plt.title("patch attack success rate")
    plt.legend()
    plt.savefig("training_pictures/patch_attack_success_rate.png")
    plt.close(0)

    # gdpa_utils.py
import torch
import torch.nn.functional as F

# ImageNet statistics
MEAN = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).cuda()
STD = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).cuda()

def normalize_imagenet(x):
    """Normalize [0,1] inputs to ImageNet stats"""
    return (x - MEAN) / STD

def denormalize_imagenet(x):
    """Denormalize ImageNet inputs back to [0,1] for Generator"""
    return x * STD + MEAN

def scale_theta(theta, theta_div):
    """Scales the predicted affine parameters"""
    # Limits shift to avoid patch going too far off screen
    mask_s = torch.tanh(theta / theta_div) * 0.8 
    return mask_s

def scale_pattern(patch, p_scale=1.0):
    """Scales patch values to valid range"""
    # Often generator outputs unbounded values, we squash to [0,1]
    return torch.sigmoid(patch)

def move_m_p(aff_theta, pattern_s, device, alpha=1.0, image_size=224):
    """
    Places the patch onto a canvas using Affine Grid Sample.
    aff_theta: (Batch, 2) -> Translation parameters (tx, ty)
    pattern_s: (Batch, 3, PatchSize, PatchSize)
    """
    bs = pattern_s.size(0)
    patch_h = pattern_s.size(2)
    
    # 1. Create a canvas with the patch in the center
    image_with_patch = torch.zeros(bs, 3, image_size, image_size, device=device)
    mask_with_patch = torch.zeros(bs, 1, image_size, image_size, device=device)
    
    # Center coordinates
    start = (image_size // 2) - (patch_h // 2)
    end = start + patch_h
    
    image_with_patch[:, :, start:end, start:end] = pattern_s
    mask_with_patch[:, :, start:end, start:end] = alpha
    
    # 2. Create Affine Matrix
    # We only use Translation (theta outputs 2 values: tx, ty)
    # Matrix: [[1, 0, tx], [0, 1, ty]]
    rot_theta = torch.tensor([[1.0, 0.0], [0.0, 1.0]]).unsqueeze(0).to(device).repeat(bs, 1, 1)
    theta_batch = torch.cat((rot_theta, aff_theta.unsqueeze(2)), 2)
    
    # 3. Apply Grid Sample (Inverse warp)
    grid = F.affine_grid(theta_batch, image_with_patch.size(), align_corners=True)
    
    # Warped Patch and Mask
    pattern_warped = F.grid_sample(image_with_patch, grid, align_corners=True)
    mask_warped = F.grid_sample(mask_with_patch, grid, align_corners=True)
    
    return mask_warped, pattern_warped

def perturb_image(inputs_normalized, mp_generator, device, devide_theta=1.0):
    """
    Full pipeline: 
    1. Denormalize input (Generator needs [0,1] content)
    2. Run Generator -> Patch & Theta
    3. Warp Patch
    4. Apply Patch to Image
    5. Return Normalized Result for Classifier
    """
    
    # Generator expects [0, 1] input range
    inputs_01 = denormalize_imagenet(inputs_normalized).clamp(0, 1)
    
    # Get Patch and Location
    _, pattern_raw, aff_theta_raw = mp_generator(inputs_01)
    
    # Process outputs
    aff_theta = scale_theta(aff_theta_raw, devide_theta)
    pattern_s = scale_pattern(pattern_raw)
    
    # Warp
    mask_s, pattern_s = move_m_p(aff_theta, pattern_s, device)
    
    # Apply to clean image (in [0,1] space)
    adv_img_01 = inputs_01 * (1 - mask_s) + pattern_s * mask_s
    adv_img_01 = adv_img_01.clamp(0, 1)
    
    # Re-normalize for classifier
    adv_img_norm = normalize_imagenet(adv_img_01)
    
    return adv_img_norm, inputs_01, adv_img_01, mask_s

# gdpa_models.py
import torch
import torch.nn as nn
import functools
from torch.nn import init

class ResnetBlock(nn.Module):
    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):
        super(ResnetBlock, self).__init__()
        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)

    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):
        conv_block = []
        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)

        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]
        if use_dropout:
            conv_block += [nn.Dropout(0.5)]

        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)
        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]

        return nn.Sequential(*conv_block)

    def forward(self, x):
        return x + self.conv_block(x)

class ResnetGenerator_small_patch(nn.Module):
    def __init__(self, patch_size, input_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False,
                 n_blocks=6, padding_type='reflect'):
        self.patch_size = patch_size
        assert (n_blocks >= 0)
        super(ResnetGenerator_small_patch, self).__init__()
        if type(norm_layer) == functools.partial:
            use_bias = norm_layer.func == nn.InstanceNorm2d
        else:
            use_bias = norm_layer == nn.InstanceNorm2d

        model_enc = [nn.ReflectionPad2d(3),
                     nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),
                     norm_layer(ngf),
                     nn.ReLU(True)]

        n_downsampling = 2
        for i in range(n_downsampling):
            mult = 2 ** i
            model_enc += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),
                          norm_layer(ngf * mult * 2),
                          nn.ReLU(True)]

        mult = 2 ** n_downsampling
        for i in range(n_blocks):
            model_enc += [
                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,
                            use_bias=use_bias)]

        self.model_enc = nn.Sequential(*model_enc)
        self.p_conv = nn.Conv2d(256, 3, kernel_size=3, stride=2, padding=1, bias=use_bias)
        self.p_norm = norm_layer(3)
        self.p_relu = nn.ReLU(True)
        
        # Calculate feature size based on downsampling. For 224x224 input with 2 downsamples: 56x56
        self.p_fc = nn.Linear(3 * 28 * 28, 3 * self.patch_size * self.patch_size)
        self.theta_fc = nn.Linear(256 * 56 * 56, 2)

    def forward(self, input):
        x = self.model_enc(input)
        # Location/Affine parameters (Theta)
        loc = self.theta_fc(x.view(x.size(0), -1))
        
        # Patch generation
        h = self.p_conv(x)
        h = self.p_norm(h)
        # Note: The original repo hardcoded view sizes, adapted here for safety
        h = self.p_relu(h)
        h = F.adaptive_avg_pool2d(h, (28, 28)) # Ensure size matches linear layer
        h = h.view(h.size(0), -1) 
        
        patch = self.p_fc(h).view(-1, 3, self.patch_size, self.patch_size)
        return 1, patch, loc

import torch.nn.functional as F

def get_norm_layer():
    return functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)

def init_weights(net, init_type='normal', init_gain=0.02):
    def init_func(m):
        classname = m.__class__.__name__
        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):
            if init_type == 'normal':
                init.normal_(m.weight.data, 0.0, init_gain)
            elif init_type == 'xavier':
                init.xavier_normal_(m.weight.data, gain=init_gain)
            if hasattr(m, 'bias') and m.bias is not None:
                init.constant_(m.bias.data, 0.0)
        elif classname.find('BatchNorm2d') != -1:
            init.normal_(m.weight.data, 1.0, init_gain)
            init.constant_(m.bias.data, 0.0)
    net.apply(init_func)

def load_generator(patch_size, input_nc, ngf, device):
    norm_layer = get_norm_layer()
    net = ResnetGenerator_small_patch(patch_size, input_nc, ngf, norm_layer=norm_layer)
    init_weights(net)
    return net.to(device)

# GDPA_Attack.py
import torch
import torch.nn as nn
import torchvision
from torchvision import models
import argparse
import csv
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

from utils import dataloader
from gdpa_models import load_generator
from gdpa_utils import perturb_image

parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', type=int, default=16, help="batch size") # Increased default for training gen
parser.add_argument('--num_workers', type=int, default=2, help="num_workers")
parser.add_argument('--train_size', type=int, default=5000, help="number of training images")
parser.add_argument('--test_size', type=int, default=1000, help="number of test images")
parser.add_argument('--patch_size', type=int, default=50, help="size of the square patch")
parser.add_argument('--lr_gen', type=float, default=0.0002, help="generator learning rate")
parser.add_argument('--target', type=int, default=859, help="target label (toaster)")
parser.add_argument('--epochs', type=int, default=10, help="total epoch")
parser.add_argument('--data_dir', type=str, default='./data', help="dir of the dataset")
parser.add_argument('--GPU', type=str, default='0', help="index of used GPU")
parser.add_argument('--log_dir', type=str, default='gdpa_attack_log.csv', help='dir of the log')
parser.add_argument('--beta', type=float, default=3000.0, help="scaling factor for location (higher = more centered initially)")
args = parser.parse_args()

os.environ["CUDA_VISIBLE_DEVICES"] = args.GPU
os.makedirs("gdpa_results", exist_ok=True)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def main():
    # 1. Load Data
    print("Loading Data...")
    train_loader, test_loader = dataloader(args.train_size, args.test_size, args.data_dir, args.batch_size, args.num_workers)

    # 2. Load Victim Model (Frozen)
    print("Loading Victim Model (ResNet50)...")
    model = models.resnet50(pretrained=True).to(device)
    model.eval()
    for param in model.parameters():
        param.requires_grad = False

    # 3. Load GDPA Generator
    print("Loading Generator...")
    # input_nc=3 (RGB), ngf=64 (Filters)
    mp_generator = load_generator(args.patch_size, 3, 64, device)
    
    # Optimizer for Generator
    optimizer_gen = torch.optim.Adam(mp_generator.parameters(), lr=args.lr_gen, betas=(0.5, 0.999))
    
    # Loss function (Targeted Attack)
    criterion = nn.CrossEntropyLoss()
    
    # Logging
    with open(args.log_dir, 'w') as f:
        writer = csv.writer(f)
        writer.writerow(["epoch", "train_asr", "test_asr", "avg_loss"])

    print(f"Starting Training for {args.epochs} epochs. Target Class: {args.target}")

    for epoch in range(args.epochs):
        # --- Training Phase ---
        mp_generator.train()
        total_train = 0
        success_train = 0
        total_loss = 0
        
        train_bar = tqdm(train_loader, desc=f"Epoch {epoch} Train")
        
        for images, labels in train_bar:
            images, labels = images.to(device), labels.to(device)
            bs = images.size(0)
            
            # Create target labels (Targeted Attack)
            target_labels = torch.full((bs,), args.target, dtype=torch.long).to(device)
            
            # Zero Grads
            optimizer_gen.zero_grad()
            
            # Generate Attack
            # adv_images_norm is ready for ResNet. 
            adv_images_norm, _, _, _ = perturb_image(images, mp_generator, device, devide_theta=args.beta)
            
            # Forward Pass Victim
            outputs = model(adv_images_norm)
            
            # Calculate Loss
            # We want to MINIMIZE CrossEntropy between output and TARGET class
            loss = criterion(outputs, target_labels)
            
            # Backprop
            loss.backward()
            optimizer_gen.step()
            
            # Stats
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += bs
            success_train += (predicted == target_labels).sum().item()
            
            train_bar.set_postfix({'ASR': f"{100*success_train/total_train:.2f}%", 'Loss': f"{loss.item():.4f}"})

        train_asr = success_train / total_train

        # --- Testing Phase ---
        mp_generator.eval()
        total_test = 0
        success_test = 0
        
        # For visualization saving
        saved_vis = False
        
        test_bar = tqdm(test_loader, desc=f"Epoch {epoch} Test")
        
        with torch.no_grad():
            for images, labels in test_bar:
                images, labels = images.to(device), labels.to(device)
                bs = images.size(0)
                target_labels = torch.full((bs,), args.target, dtype=torch.long).to(device)
                
                # Generate Attack
                # adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device)
                adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device, devide_theta=args.beta)

                
                outputs = model(adv_images_norm)
                _, predicted = torch.max(outputs.data, 1)
                
                total_test += bs
                success_test += (predicted == target_labels).sum().item()
                
                # Save Visualization for the first batch of the epoch
                if not saved_vis:
                    save_visualization(inputs_01, adv_01, mask, epoch)
                    saved_vis = True

        test_asr = success_test / total_test
        print(f"Epoch {epoch} Result: Train ASR: {train_asr:.2%}, Test ASR: {test_asr:.2%}")

        # Save Checkpoint
        torch.save(mp_generator.state_dict(), f"gdpa_results/generator_epoch_{epoch}.pth")
        
        # Log
        with open(args.log_dir, 'a') as f:
            writer = csv.writer(f)
            writer.writerow([epoch, train_asr, test_asr, total_loss/len(train_loader)])

def save_visualization(clean_batch, adv_batch, mask_batch, epoch):
    """Saves a comparison image of the first item in batch"""
    clean = clean_batch[0].cpu().permute(1, 2, 0).numpy()
    adv = adv_batch[0].cpu().permute(1, 2, 0).numpy()
    mask = mask_batch[0].cpu().permute(1, 2, 0).numpy()
    
    fig, axs = plt.subplots(1, 3, figsize=(12, 4))
    axs[0].imshow(clean)
    axs[0].set_title("Clean")
    axs[0].axis('off')
    
    axs[1].imshow(mask, cmap='gray')
    axs[1].set_title("Generated Mask/Patch")
    axs[1].axis('off')
    
    axs[2].imshow(adv)
    axs[2].set_title("Adversarial")
    axs[2].axis('off')
    
    plt.tight_layout()
    plt.savefig(f"gdpa_results/vis_epoch_{epoch}.png")
    plt.close()

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torchvision
from torchvision import models
import argparse
import csv
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

from utils import dataloader
from gdpa_models import load_generator
from gdpa_utils import perturb_image

parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', type=int, default=16, help="batch size")
parser.add_argument('--num_workers', type=int, default=2, help="num_workers")
parser.add_argument('--train_size', type=int, default=5000, help="number of training images")
parser.add_argument('--test_size', type=int, default=1000, help="number of test images")
parser.add_argument('--patch_size', type=int, default=50, help="size of the square patch")
parser.add_argument('--lr_gen', type=float, default=0.0002, help="generator learning rate")
# Note: --target argument removed as it is not needed for untargeted attacks
parser.add_argument('--epochs', type=int, default=10, help="total epoch")
parser.add_argument('--data_dir', type=str, default='./data', help="dir of the dataset")
parser.add_argument('--GPU', type=str, default='0', help="index of used GPU")
parser.add_argument('--log_dir', type=str, default='gdpa_untargeted_log.csv', help='dir of the log')
parser.add_argument('--beta', type=float, default=3000.0, help="scaling factor for location (higher = more centered initially)")
args = parser.parse_args()

os.environ["CUDA_VISIBLE_DEVICES"] = args.GPU
os.makedirs("gdpa_untargeted_results", exist_ok=True)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def main():
    # 1. Load Data
    print("Loading Data...")
    train_loader, test_loader = dataloader(args.train_size, args.test_size, args.data_dir, args.batch_size, args.num_workers)

    # 2. Load Victim Model (Frozen)
    print("Loading Victim Model (ResNet50)...")
    model = models.resnet50(pretrained=True).to(device)
    model.eval()
    for param in model.parameters():
        param.requires_grad = False

    # 3. Load GDPA Generator
    print("Loading Generator...")
    mp_generator = load_generator(args.patch_size, 3, 64, device)
    
    # Optimizer for Generator
    optimizer_gen = torch.optim.Adam(mp_generator.parameters(), lr=args.lr_gen, betas=(0.5, 0.999))
    
    # Loss function
    criterion = nn.CrossEntropyLoss()
    
    # Logging
    with open(args.log_dir, 'w') as f:
        writer = csv.writer(f)
        writer.writerow(["epoch", "train_asr", "test_asr", "avg_loss"])

    print(f"Starting UNTARGETED Training for {args.epochs} epochs.")

    for epoch in range(args.epochs):
        # --- Training Phase ---
        mp_generator.train()
        total_train = 0
        success_train = 0
        total_loss = 0
        
        train_bar = tqdm(train_loader, desc=f"Epoch {epoch} Train")
        
        for images, labels in train_bar:
            images, labels = images.to(device), labels.to(device)
            bs = images.size(0)
            
            # Zero Grads
            optimizer_gen.zero_grad()
            
            # Generate Attack
            adv_images_norm, _, _, _ = perturb_image(images, mp_generator, device, devide_theta=args.beta)
            
            # Forward Pass Victim
            outputs = model(adv_images_norm)
            
            # --- CRITICAL CHANGE: UNTARGETED LOSS ---
            # We want to MAXIMIZE the error on the true labels.
            # Optimizer minimizes, so we Minimize (-Loss)
            loss = -criterion(outputs, labels)
            
            # Backprop
            loss.backward()
            optimizer_gen.step()
            
            # Stats
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += bs
            
            # Success = Prediction is NOT the ground truth
            success_train += (predicted != labels).sum().item()
            
            train_bar.set_postfix({'ASR': f"{100*success_train/total_train:.2f}%", 'Loss': f"{loss.item():.4f}"})

        train_asr = success_train / total_train

        # --- Testing Phase ---
        mp_generator.eval()
        total_test = 0
        success_test = 0
        saved_vis = False
        
        test_bar = tqdm(test_loader, desc=f"Epoch {epoch} Test")
        
        with torch.no_grad():
            for images, labels in test_bar:
                images, labels = images.to(device), labels.to(device)
                bs = images.size(0)
                
                # Generate Attack
                # adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device)
                adv_images_norm, inputs_01, adv_01, mask = perturb_image(images, mp_generator, device, devide_theta=args.beta)
                
                outputs = model(adv_images_norm)
                _, predicted = torch.max(outputs.data, 1)
                
                total_test += bs
                # Success = Prediction is NOT the ground truth
                success_test += (predicted != labels).sum().item()
                
                # Save Visualization
                if not saved_vis:
                    save_visualization(inputs_01, adv_01, mask, epoch)
                    saved_vis = True

        test_asr = success_test / total_test
        print(f"Epoch {epoch} Result: Train ASR: {train_asr:.2%}, Test ASR: {test_asr:.2%}")

        # Save Checkpoint
        torch.save(mp_generator.state_dict(), f"gdpa_untargeted_results/generator_epoch_{epoch}.pth")
        
        # Log
        with open(args.log_dir, 'a') as f:
            writer = csv.writer(f)
            writer.writerow([epoch, train_asr, test_asr, total_loss/len(train_loader)])

def save_visualization(clean_batch, adv_batch, mask_batch, epoch):
    """Saves a comparison image of the first item in batch"""
    clean = clean_batch[0].cpu().permute(1, 2, 0).numpy()
    adv = adv_batch[0].cpu().permute(1, 2, 0).numpy()
    mask = mask_batch[0].cpu().permute(1, 2, 0).numpy()
    
    fig, axs = plt.subplots(1, 3, figsize=(12, 4))
    axs[0].imshow(clean)
    axs[0].set_title("Clean")
    axs[0].axis('off')
    
    axs[1].imshow(mask, cmap='gray')
    axs[1].set_title("Generated Mask/Patch")
    axs[1].axis('off')
    
    axs[2].imshow(adv)
    axs[2].set_title("Adversarial (Untargeted)")
    axs[2].axis('off')
    
    plt.tight_layout()
    plt.savefig(f"gdpa_untargeted_results/vis_epoch_{epoch}.png")
    plt.close()

if __name__ == "__main__":
    main()

# gdpa_vis_untargeted.py
import torch
import torchvision
from torchvision import models, transforms
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import os
import json
import urllib.request

from gdpa_models import load_generator
from gdpa_utils import perturb_image

# --- Configuration ---
DATA_DIR = './data'
# MAKE SURE TO POINT TO THE NEW UNTARGETED MODEL FOLDER
GENERATOR_PATH = 'gdpa_results/generator_epoch_3.pth' 
PATCH_SIZE = 60         
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
OUTPUT_FILE = "gdpa_untargeted_vis.png"
CLEAN_TENSOR_FILE = "clean_img_tensor.pt"
ADV_TENSOR_FILE = "adv_img_tensor.pt"


# --- Helpers ---
def get_imagenet_labels():
    url = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
    try:
        with urllib.request.urlopen(url) as response:
            labels = json.loads(response.read())
        return labels
    except:
        return None

labels_map = get_imagenet_labels()

def get_label_name(index):
    if labels_map:
        return f"{index}: {labels_map[index]}"
    return f"Class {index}"

def main():
    # 1. Load Model
    model = models.resnet50(pretrained=True).to(DEVICE)
    model.eval()

    # 2. Load Generator
    if not os.path.exists(GENERATOR_PATH):
        print(f"Error: {GENERATOR_PATH} not found. Run GDPA_Attack_Untargeted.py first.")
        return

    mp_generator = load_generator(PATCH_SIZE, 3, 64, DEVICE)
    mp_generator.load_state_dict(torch.load(GENERATOR_PATH, map_location=DEVICE))
    mp_generator.eval()

    # 3. Load Data
    norm_mean = [0.485, 0.456, 0.406]
    norm_std = [0.229, 0.224, 0.225]
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean, norm_std)
    ])
    try:
        testset = torchvision.datasets.Imagenette(root=DATA_DIR, split='val', size='full', download=True, transform=transform)
        testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)
        image, label = next(iter(testloader))
    except:
        image = torch.randn(1, 3, 224, 224)
        label = torch.tensor([0])

    image = image.to(DEVICE)
    label_idx = label.item()

    # 4. Attack
    with torch.no_grad():
        adv_norm, inputs_01, adv_01, mask = perturb_image(image, mp_generator, DEVICE)
        adv_norm, inputs_01, adv_01, mask = perturb_image(image, mp_generator, DEVICE, devide_theta=3000)

    # 5. Inference
    out_clean = model(image)
    top_clean = torch.argmax(out_clean, 1).item()
    conf_clean = torch.nn.functional.softmax(out_clean, dim=1)[0][top_clean].item()

    out_adv = model(adv_norm)
    top_adv = torch.argmax(out_adv, 1).item()
    conf_adv = torch.nn.functional.softmax(out_adv, dim=1)[0][top_adv].item()

    # 6. Save Tensors (Upscaled to 512x512)
    print(f"Saving 512x512 tensors to {CLEAN_TENSOR_FILE} and {ADV_TENSOR_FILE}...")
    
    # Interpolate
    clean_512 = F.interpolate(inputs_01, size=(512, 512), mode='bilinear', align_corners=False)
    adv_512 = F.interpolate(adv_01, size=(512, 512), mode='bilinear', align_corners=False)
    
    # --- FIX: CLAMP VALUES BEFORE SAVING ---
    clean_512 = torch.clamp(clean_512, 0.0, 1.0)
    adv_512 = torch.clamp(adv_512, 0.0, 1.0)
    # ---------------------------------------

    torch.save(clean_512.detach().cpu(), CLEAN_TENSOR_FILE)
    torch.save(adv_512.detach().cpu(), ADV_TENSOR_FILE)

    # 7. Visualize
    img_clean_vis = inputs_01[0].permute(1, 2, 0).cpu().numpy()
    img_adv_vis = adv_01[0].permute(1, 2, 0).cpu().numpy()
    mask_vis = mask[0].permute(1, 2, 0).cpu().numpy()

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    axes[0].imshow(img_clean_vis)
    axes[0].set_title(f"Clean (True: {get_label_name(label_idx)})\nPred: {get_label_name(top_clean)}\nConf: {conf_clean:.2%}")
    axes[0].axis('off')

    axes[1].imshow(mask_vis, cmap='gray')
    axes[1].set_title("Generated Mask")
    axes[1].axis('off')

    # Logic for Untargeted Success: Prediction != True Label
    is_success = (top_adv != label_idx)
    color = 'green' if is_success else 'red'
    
    axes[2].imshow(img_adv_vis)
    axes[2].set_title(f"Untargeted Attack\nPred: {get_label_name(top_adv)}\nConf: {conf_adv:.2%}", color=color)
    axes[2].axis('off')

    plt.tight_layout()
    plt.savefig(OUTPUT_FILE)
    print(f"Saved visualization to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
